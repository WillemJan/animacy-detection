\documentclass[a4paper,UKenglish]{oasics}

\usepackage{microtype, graphicx, booktabs, multirow, color, colortbl}

\usepackage{blindtext}
\bibliographystyle{plain}

\definecolor{Gray}{gray}{0.9}
\usepackage[utf8]{inputenc}

\title{Animacy Detection in Folktales}
\author[1]{Folgert Karsdorp}
\author[2]{Antal van den Bosch}
\affil[1]{Meertens Institute\\
  Amsterdam, The Netherlands\\
  \texttt{folgert.karsdorp@meertens.knaw.nl}}
\affil[2]{Radboud University\\
  Nijmegen, The Netherlands\\
  \texttt{a.vandenbosch@let.ru.nl}}
\authorrunning{F. Karsdorp and A. van den Bosch}
\Copyright{Folgert Karsdorp and Antal van den Bosch}
\subjclass{machine learning}
\keywords{machine learning}

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\serieslogo{}%please provide filename (without suffix)
\volumeinfo%(easychair interface)
  {Billy Editor and Bill Editors}% editors
  {2}% number of editors: 1, 2, ....
  {Conference/workshop/symposium title on which this volume is based on}% event
  {1}% volume
  {1}% issue
  {1}% starting page number
\EventShortName{}
\DOI{10.4230/OASIcs.xxx.yyy.p}% to be completed by the volume editor
% Editor-only macros::end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}
\maketitle

\begin{abstract}
\blindtext[1]
\end{abstract}

\section{Introduction}

\section{Previous Work}

\subsection{Definitions of Animacy}
In most of the literature on automatic animacy detection, people make
a binary distinction between animate and inanimate. \cite{bowman:12}
for example, define objects to be animate if they are alive and have
the ability to move under their own will. \cite{orasan:07} define animacy
in the context of anaphora resolution: ``if its referent can also be
referred to using one of the pronouns he, she, him, her, his, hers,
himself, herself, or a combination of such pro- nouns (e.g. his/her
)'' Not only are some parts of these definitions somewhat circular, we
believe that they are both essentialistic and not particularly suited
for the rich and wondrous entities that live in the realm of
folktales. A more sophisticated way to handle the distinction between
animate and inanimate objects is given by Dennett CITE who argues that
animacy and aliveness should be treated as epistemological stances
rather than fixed states in the world.

\subsection{Methods for Automatic Animacy Detection}


\section{The Data, Annotation and Preprocessing}

\subsection{The Data}
Our corpus consists of 74 Dutch folktales from the collection
\textit{Volkssprookjes uit Nederland en Vlaanderen} compiled by
\cite{sinninghe:78}. The collection contains retellings of popular
folktales from the Netherlands and Flanders, such as \textit{The
  Bremen Town Musicians} (ATU 130) and \textit{The Table, the Ass, and
  the Stick } (ATU 563). Some of the less well-know stories are
\textit{Cock, Hen, Duck, Pin, and Needle on a Journey} (AT 0210) and
(ATU 780) \textit{The Singing Bone}. A digital version of the
collection available in the Dutch Folktale Database from the Meertens
Institute (corpus SINVSUNV.20E).\footnote{See
  \url{http://www.verhalenbank.nl}} We chose this collection because
of its homogeneity while it still displays enough diversity: (1) all
tales are written in standard Dutch, (2) the stories are edited by the
same editor, (3) the tales have a comparable length and (4) the
collection contains tales from a number of different genres, such as
fairy tales, legends, riddles etc.

\subsection{Annotation}
We labeled the corpus for animacy using the definition provided by
%\cite{bowman:12}:

\subsection{Preprocessing}


\section{Experimental Setup}
This section describes our experimental setup including the features
used, the machine learning models we applied and our methods of
evaluation.

\subsection{Task description}

\subsection{Features}

We explore a range of different features and feature combinations
including lexical features, morphological features, syntactic features
and semantic features.

\begin{description}
\item[Lexical features]
We take a sliding window approach where for each focus word (i.e.\ the
word for which we want to predict whether it is animate or not) we
extract $n$ words to the left, $n$ words to the right and the focus
word itself. In all experiments we set $n$ to 3. In addition to the
word forms, we extract for each word in a window the lemmata
corresponding to the words.

\item[Morphological Features]
For each word we extract its Part-of-Speech tag. For reasons of
comparability for choose to use the tags as provided by the
output of the syntactic parser, instead of a more specialized
Part-of-Speech tagger. Again, we take a sliding window approach and
extract the Part-of-Speech tags for $n$ word left of the focus word
and $n$ word right of the focus word as well as the tag of the focus
word itself.

\item[Syntactic Features]
We extract the dependency tag for each word and its $n$ neighbors to
the right and to the left as provided by the syntactic parser
Alpino. Animate entities tend to take subject or object positions in a
sentences which is why this feature is expected and has proven to
perform rather well.

\item[Semantic Features]
For each focus word we add a 300 dimension vector representation that
was learned by applying word2vec on the Dutch version of CoW. Missing
words were given a vector were all dimensions are set to zero.

\end{description}


\subsection{Models}
We make use of a Logistic Regression classifier also know as a Maximum
Entropy classifier with L2 regularization as implemented in
\cite{sklearn}. In all experiments, we set the regularization strength
parameter $C$ to 1.

We compare nine models in which we make use of different feature
combinations: (1) words, (2) words and Part-of-Speech tags, (3)
words, Part-of-Speech tags and lemmata, (4) words, Part-of-Speech
tags, lemmata and dependency tags, (5) word embeddings and (6-9) the
features in model 1 to 4 plus word embeddings.

\subsection{Evaluation}

Animate words are far outnumbered by the inanimate words in our
collection. Reporting accuracy scores would therefore provide
distorted results to much in favor of the majority category. The
rarity of animate words make evaluation measures such as the
well-known F1-score more appropriate. For all experiments we report on
the precision, recall and F1-score \cite{rijsbergen:79}. In most of
the literature on animacy detection results are only given for the
classification of nouns. We will report the results for all words in a
text and on those specifically for nouns separately.

\section{Results}



\begin{table*}
\centering
\begin{tabular}{llrrrr}
\toprule
features                                                 &           & precision & recall & $F1$ \\ \midrule
\multirow{2}{*}{word}                                    & animate   & 0.93      & 0.80   & 0.86 \\
                                                         & inanimate & 0.96      & 0.99   & 0.98 \\
\multirow{2}{*}{word + PoS}                              & animate   & 0.92      & 0.88   & 0.90 \\
                                                         & inanimate & 0.98      & 0.99   & 0.98 \\
\multirow{2}{*}{word + PoS + lemma}                      & animate   & 0.92      & 0.88   & 0.90 \\
                                                         & inanimate & 0.98      & 0.99   & 0.98 \\
\multirow{2}{*}{word + PoS + lemma + dep}                & animate   & 0.93      & 0.88   & 0.90 \\
                                                         & inanimate & 0.98      & 0.99   & 0.98 \\
\multirow{2}{*}{word + embeddings}                       & animate   & 0.93      & 0.89   & 0.91 \\
                                                         & inanimate & 0.98      & 0.99   & 0.98 \\
\rowcolor{Gray}                                          & animate   & 0.93      & 0.93   & 0.93 \\
\rowcolor{Gray}\multirow{-2}{*}{word + PoS + embeddings} & inanimate & 0.99      & 0.99   & 0.99 \\
\multirow{2}{*}{word + PoS + lemma + embeddings}         & animate   & 0.93      & 0.93   & 0.93 \\
                                                         & inanimate & 0.99      & 0.99   & 0.99 \\
\multirow{2}{*}{word + PoS + lemma + dep + embeddings}   & animate   & 0.92      & 0.93   & 0.93 \\
                                                         & inanimate & 0.99      & 0.99   & 0.99 \\
\multirow{2}{*}{embeddings}                              & animate   & 0.90      & 0.76   & 0.83 \\
                                                         & inanimate & 0.96      & 0.98   & 0.97 \\

\bottomrule
\end{tabular}
\caption{Precision, recall and $F1$ scores for animate and inanimate classes per feature settings for all words.}
\label{tab:results-all}
\end{table*}

\begin{table*}
\centering
\begin{tabular}{llrrrr}
\toprule
features                                               &           & precision & recall & $F1$ \\ \midrule
\multirow{2}{*}{word}                                  & animate   & 0.64      & 0.96   & 0.77 \\
                                                       & inanimate & 0.98      & 0.81   & 0.89 \\
\multirow{2}{*}{word + PoS}                            & animate   & 0.80      & 0.92   & 0.86 \\
                                                       & inanimate & 0.95      & 0.89   & 0.92 \\
\multirow{2}{*}{word + PoS + lemma}                    & animate   & 0.80      & 0.92   & 0.86 \\
                                                       & inanimate & 0.95      & 0.89   & 0.92 \\
\multirow{2}{*}{word + PoS + lemma + dep}              & animate   & 0.80      & 0.93   & 0.86 \\
                                                       & inanimate & 0.96      & 0.88   & 0.92 \\
\multirow{2}{*}{word + embeddings}                     & animate   & 0.83      & 0.93   & 0.88 \\
                                                       & inanimate & 0.96      & 0.90   & 0.93 \\
\rowcolor{Gray}                                        & animate   & 0.92      & 0.92   & 0.92 \\
\rowcolor{Gray}\multirow{-2}{*}{word + PoS + embeddings} & inanimate & 0.95    & 0.95   & 0.95 \\
\multirow{2}{*}{word + PoS + lemma + embeddings}       & animate   & 0.92      & 0.92   & 0.92 \\
                                                       & inanimate & 0.95      & 0.95   & 0.95 \\
\multirow{2}{*}{word + PoS + lemma + dep + embeddings} & animate   & 0.91      & 0.92   & 0.92 \\
                                                       & inanimate & 0.95      & 0.95   & 0.95 \\
\multirow{2}{*}{embeddings}                            & animate   & 0.66      & 0.88   & 0.75 \\
                                                       & inanimate & 0.94      & 0.81   & 0.87 \\

\bottomrule
\end{tabular}
\caption{Precision, recall and $F1$ scores for animate and inanimate classes
  per feature settings for all words tagged as noun.}
\label{tab:results-noun}
\end{table*}

\section{Concluding Remarks}

\section*{Acknowledgments}

The work on which this paper is based has been supported by the
Computational Humanities Programme of the Royal Netherlands Academy of
Arts and Sciences, under the auspices of the Tunes \& Tales
project. For further information, see \url{http://ehumanities.nl}.

Constantin Oraˇsan and Richard J. Evans. 2007. NP an- imacy identification for anaphora resolution. Journal of Artificial Intelligence Research (JAIR), 29:79–103.
\begin{thebibliography}{50}
\bibitem{sinninghe:78} Sinninghe J. \textit{Volkssprookjes uit
    Nederland en Vlaanderen}. Kruseman, Den Haag, 1978.
\bibitem{sklearn} Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay,
         E. `Scikit-Learn: Machine Learning in {P}ython'. In:
         \textit{Journal of Machine Learning Research}, 12,
         2825--2830, 2011.
\bibitem{rijsbergen:79} {Van Rijsbergen}, C. \textit{Information
    Retrieval}. Butterworths.
\bibitem{bowman:12} Bowman S. and Chopra, H. `Automatic animacy
  classification'. In \textit{Proceedings of the NAACL - HLT 2012
    Student Research Workshop}, 2012.
\bibitem{orasan:07} Or\u{a}san, C. and Evans, R. `NP animacy
  identification for anaphora resolution'. In \textit{Journal of
    Artificial Intelligence Research}, 29, 79--103, 2007.
\end{thebibliography}

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
